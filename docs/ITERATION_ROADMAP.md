# ğŸš€ é¡¹ç›®æ·±åº¦è¿­ä»£æ”¹è¿›è·¯çº¿å›¾

> åŸºäºä»£ç å®¡æŸ¥ä¸å¼€æºç¤¾åŒºæœ€ä½³å®è·µåˆ†æï¼ˆ2026å¹´1æœˆï¼‰

---

## ğŸ“Š å½“å‰é¡¹ç›®è¯„ä¼°

### âœ… ä¼˜åŠ¿
- **æ¶æ„è®¾è®¡ä¼˜ç§€**ï¼šé‡‡ç”¨ Clean Architecture + DDDï¼Œå±‚æ¬¡åˆ†æ˜
- **å¯æ‰©å±•æ€§å¼º**ï¼šç«¯å£-é€‚é…å™¨æ¨¡å¼ï¼Œæ˜“äºæ·»åŠ æ–°çš„æŠ“å–å™¨/æ‘˜è¦å™¨/å¯¼å‡ºå™¨
- **ä»£ç è´¨é‡é«˜**ï¼šç±»å‹æ³¨è§£å®Œå–„ã€å¼‚å¸¸å¤„ç†è§„èŒƒã€æ—¥å¿—è®°å½•å®Œæ•´
- **åŠŸèƒ½ä¸°å¯Œ**ï¼šæ”¯æŒå¤šç§ AI æ‘˜è¦ã€å¤šç§å¯¼å‡ºæ ¼å¼ã€æ‰¹é‡å¤„ç†

### âœ… å·²å®Œæˆæ”¹è¿›ï¼ˆ2026å¹´1æœˆï¼‰
- âœ… MCP æœåŠ¡æ”¯æŒ - å·²å®ç° `mcp-server` CLI å‘½ä»¤
- âœ… MapReduce åˆ†å—æ‘˜è¦å™¨ - æ”¯æŒè¶…é•¿æ–‡æœ¬å¤„ç†
- âœ… æ’ä»¶ç³»ç»Ÿ - æ”¯æŒé€šè¿‡ entry_points åŠ è½½ç¬¬ä¸‰æ–¹æ’ä»¶
- âœ… æ‘˜è¦è´¨é‡è¯„ä¼°å¢å¼º - å¹»è§‰æ£€æµ‹ã€ä¿¡æ¯å¯†åº¦ã€BERTScore æ”¯æŒ

### âš ï¸ å¾…æ”¹è¿›ç©ºé—´
- GUI ä»£ç è¾ƒä¸ºåºå¤§ï¼ˆ233KBï¼‰
- RAG å¢å¼ºæ‘˜è¦ï¼ˆå¾…å®ç°ï¼‰

---

## ğŸ¯ è¿­ä»£æ”¹è¿›è®¡åˆ’

### ç¬¬ä¸€é˜¶æ®µï¼šMCP æœåŠ¡æ”¯æŒ â­â­â­â­â­ âœ… å·²å®Œæˆ

**èƒŒæ™¯**ï¼š<cite index="23-18,23-19,23-20">MCP (Model Context Protocol) æ˜¯ä¸“ä¸º LLM äº¤äº’è®¾è®¡çš„æ ‡å‡†åŒ–åè®®ï¼Œè®©åº”ç”¨å¯ä»¥å®‰å…¨åœ°å‘ LLM æä¾›æ•°æ®å’ŒåŠŸèƒ½</cite>ã€‚

**å®ç°æ–¹æ¡ˆ**ï¼š

```python
# src/wechat_summarizer/mcp/server.py
from mcp import FastMCP

mcp = FastMCP("WeChat Article Summarizer")

@mcp.tool
async def fetch_article(url: str) -> dict:
    """æŠ“å–å¾®ä¿¡å…¬ä¼—å·æ–‡ç« """
    container = get_container()
    article = container.fetch_use_case.execute(url)
    return {
        "title": article.title,
        "author": article.author,
        "content": article.content_text,
        "word_count": article.word_count,
    }

@mcp.tool
async def summarize_article(url: str, method: str = "simple") -> dict:
    """æŠ“å–å¹¶æ‘˜è¦æ–‡ç« """
    container = get_container()
    article = container.fetch_use_case.execute(url)
    summary = container.summarize_use_case.execute(article, method=method)
    return {
        "title": article.title,
        "summary": summary.content,
        "key_points": list(summary.key_points),
        "tags": list(summary.tags),
    }

@mcp.resource("article://{url}")
async def get_article_resource(url: str) -> str:
    """ä½œä¸ºèµ„æºæä¾›æ–‡ç« å†…å®¹"""
    container = get_container()
    article = container.fetch_use_case.execute(url)
    return article.content_text
```

**ä¾èµ–æ·»åŠ **ï¼š
```toml
# pyproject.toml
[project.optional-dependencies]
mcp = ["mcp>=1.2.0"]
```

**ä»·å€¼**ï¼š
- å¯è¢« Claudeã€ChatGPT ç­‰ AI Agent ç›´æ¥è°ƒç”¨
- æ”¯æŒ Cursorã€VS Code ç­‰ IDE é›†æˆ
- ç¬¦åˆæœªæ¥ AI å·¥å…·ç”Ÿæ€å‘å±•æ–¹å‘

---

### ç¬¬äºŒé˜¶æ®µï¼šå¢å¼ºæ‘˜è¦ç­–ç•¥ â­â­â­â­ âœ… MapReduce å·²å®Œæˆ

**é—®é¢˜**ï¼šå½“å‰æ‘˜è¦ç­–ç•¥å¯¹é•¿æ–‡æœ¬æ•ˆæœæœ‰é™ã€‚

**æ”¹è¿›æ–¹æ¡ˆ 1ï¼šMapReduce åˆ†å—æ‘˜è¦**

<cite index="13-5,13-6,13-7">MapReduce æ–¹æ³•å°†æ–‡æ¡£åˆ†å—ã€åˆ†åˆ«æ‘˜è¦ã€å†åˆå¹¶æ€»ç»“ï¼Œè¿™åæ˜ äº†äººç±»é˜…è¯»é•¿æ–‡æœ¬çš„æ–¹å¼</cite>ã€‚

```python
# src/wechat_summarizer/infrastructure/adapters/summarizers/mapreduce.py
class MapReduceSummarizer(BaseSummarizer):
    """MapReduce åˆ†å—æ‘˜è¦å™¨"""
    
    def __init__(self, base_summarizer: SummarizerPort, chunk_size: int = 4000):
        self._base = base_summarizer
        self._chunk_size = chunk_size
    
    def summarize(self, content: ArticleContent, ...) -> Summary:
        text = content.text
        
        # 1. Map: åˆ†å—å¹¶æ‘˜è¦
        chunks = self._semantic_chunk(text, self._chunk_size)
        chunk_summaries = [
            self._base.summarize(ArticleContent.from_text(chunk))
            for chunk in chunks
        ]
        
        # 2. Reduce: åˆå¹¶æ‘˜è¦
        combined = "\n".join(s.content for s in chunk_summaries)
        final_summary = self._base.summarize(ArticleContent.from_text(combined))
        
        return final_summary
    
    def _semantic_chunk(self, text: str, max_size: int) -> list[str]:
        """è¯­ä¹‰åˆ†å—ï¼ˆæŒ‰æ®µè½è¾¹ç•Œï¼‰"""
        paragraphs = text.split("\n\n")
        chunks = []
        current_chunk = []
        current_size = 0
        
        for para in paragraphs:
            if current_size + len(para) > max_size and current_chunk:
                chunks.append("\n\n".join(current_chunk))
                current_chunk = []
                current_size = 0
            current_chunk.append(para)
            current_size += len(para)
        
        if current_chunk:
            chunks.append("\n\n".join(current_chunk))
        
        return chunks
```

**æ”¹è¿›æ–¹æ¡ˆ 2ï¼šRAG å¢å¼ºæ‘˜è¦**

<cite index="12-3,12-4">RAG é€šè¿‡åœ¨æºå†…å®¹ä¸­æ£€ç´¢ç›¸å…³ç‰‡æ®µæ¥å¢å¼ºæ‘˜è¦ï¼Œå‡å°‘å¹»è§‰å¹¶ç¡®ä¿äº‹å®ä¸€è‡´æ€§</cite>ã€‚

```python
# src/wechat_summarizer/infrastructure/adapters/summarizers/rag_enhanced.py
class RAGEnhancedSummarizer(BaseSummarizer):
    """RAG å¢å¼ºæ‘˜è¦å™¨"""
    
    def __init__(self, base_summarizer: SummarizerPort, embedder: EmbedderPort):
        self._base = base_summarizer
        self._embedder = embedder
    
    def summarize(self, content: ArticleContent, query: str = None, ...) -> Summary:
        # 1. åˆ†å—å¹¶åµŒå…¥
        chunks = self._chunk_text(content.text)
        embeddings = self._embedder.embed(chunks)
        
        # 2. æ£€ç´¢ç›¸å…³ç‰‡æ®µ
        if query:
            query_embedding = self._embedder.embed([query])[0]
            relevant_chunks = self._retrieve_top_k(chunks, embeddings, query_embedding, k=5)
        else:
            # æ— æŸ¥è¯¢æ—¶ï¼Œé€‰æ‹©ä»£è¡¨æ€§ç‰‡æ®µ
            relevant_chunks = self._select_representative(chunks, embeddings)
        
        # 3. åŸºäºæ£€ç´¢å†…å®¹ç”Ÿæˆæ‘˜è¦
        context = "\n".join(relevant_chunks)
        return self._base.summarize(ArticleContent.from_text(context))
```

---

### ç¬¬ä¸‰é˜¶æ®µï¼šæ‘˜è¦è´¨é‡è¯„ä¼°å¢å¼º â­â­â­â­ âœ… å·²å®Œæˆ

**å½“å‰çŠ¶æ€**ï¼šå·²æœ‰ ROUGE å’Œ LLM-as-Judge è¯„ä¼°ã€‚

**æ”¹è¿›æ–¹æ¡ˆï¼šæ·»åŠ æ›´å¤šè¯„ä¼°ç»´åº¦**

<cite index="15-3,15-4,15-5">å¯ä»¥æ£€æµ‹å¹»è§‰å¤±è´¥ï¼ˆæ‘˜è¦ä¸­æœ‰åŸæ–‡æ²¡æœ‰çš„ä¿¡æ¯ï¼‰ã€çŸ›ç›¾å¤±è´¥ã€ä¿¡æ¯ç¼ºå¤±å¤±è´¥</cite>ã€‚

```python
# æ‰©å±• EvaluationResult
@dataclass
class EnhancedEvaluationResult(EvaluationResult):
    """å¢å¼ºè¯„ä¼°ç»“æœ"""
    
    # äº‹å®ä¸€è‡´æ€§æ£€æŸ¥
    hallucination_score: float | None = None  # å¹»è§‰æ£€æµ‹åˆ†æ•°
    contradiction_count: int = 0              # çŸ›ç›¾æ•°é‡
    
    # ä¿¡æ¯è¦†ç›–æ£€æŸ¥
    key_facts_coverage: float | None = None   # å…³é”®äº‹å®è¦†ç›–ç‡
    missing_facts: list[str] | None = None    # ç¼ºå¤±çš„å…³é”®äº‹å®
    
    # BERTScore è¯­ä¹‰ç›¸ä¼¼åº¦
    bert_precision: float | None = None
    bert_recall: float | None = None
    bert_f1: float | None = None


class EnhancedSummaryEvaluator(SummaryEvaluator):
    """å¢å¼ºæ‘˜è¦è¯„ä¼°å™¨"""
    
    def evaluate_factual_consistency(self, original: str, summary: str) -> float:
        """äº‹å®ä¸€è‡´æ€§è¯„ä¼° - ä½¿ç”¨ NLI æ¨¡å‹"""
        # ä½¿ç”¨ entailment æ¨¡å‹æ£€æŸ¥æ‘˜è¦ä¸­çš„é™ˆè¿°æ˜¯å¦è¢«åŸæ–‡æ”¯æŒ
        pass
    
    def detect_hallucinations(self, original: str, summary: str) -> list[str]:
        """å¹»è§‰æ£€æµ‹ - æ‰¾å‡ºæ‘˜è¦ä¸­åŸæ–‡æ²¡æœ‰çš„äº‹å®"""
        pass
```

---

### ç¬¬å››é˜¶æ®µï¼šæ’ä»¶ç³»ç»Ÿ â­â­â­ âœ… å·²å®Œæˆ

**ç›®æ ‡**ï¼šå…è®¸ç”¨æˆ·è‡ªå®šä¹‰æŠ“å–å™¨ã€æ‘˜è¦å™¨ã€å¯¼å‡ºå™¨ã€‚

```python
# src/wechat_summarizer/infrastructure/plugins/loader.py
from importlib.metadata import entry_points

class PluginLoader:
    """æ’ä»¶åŠ è½½å™¨"""
    
    def load_scrapers(self) -> list[ScraperPort]:
        """ä» entry_points åŠ è½½æŠ“å–å™¨æ’ä»¶"""
        eps = entry_points(group="wechat_summarizer.scrapers")
        return [ep.load()() for ep in eps]
    
    def load_summarizers(self) -> dict[str, SummarizerPort]:
        """ä» entry_points åŠ è½½æ‘˜è¦å™¨æ’ä»¶"""
        eps = entry_points(group="wechat_summarizer.summarizers")
        return {ep.name: ep.load()() for ep in eps}
    
    def load_exporters(self) -> dict[str, ExporterPort]:
        """ä» entry_points åŠ è½½å¯¼å‡ºå™¨æ’ä»¶"""
        eps = entry_points(group="wechat_summarizer.exporters")
        return {ep.name: ep.load()() for ep in eps}
```

**æ’ä»¶ç¤ºä¾‹ (ç¬¬ä¸‰æ–¹åŒ…)**ï¼š
```toml
# pyproject.toml (ç¬¬ä¸‰æ–¹æ’ä»¶)
[project.entry-points."wechat_summarizer.scrapers"]
bilibili = "my_plugin:BilibiliScraper"

[project.entry-points."wechat_summarizer.summarizers"]
custom_llm = "my_plugin:CustomLLMSummarizer"
```

---

### ç¬¬äº”é˜¶æ®µï¼šæ€§èƒ½ä¼˜åŒ– â­â­â­

**1. HTTP è¿æ¥æ± ä¼˜åŒ–**

```python
# æ”¹è¿› http_client_pool.py
class GlobalHttpClientPool:
    """å…¨å±€ HTTP è¿æ¥æ± """
    
    _instance: httpx.AsyncClient | None = None
    _lock = asyncio.Lock()
    
    @classmethod
    async def get_client(cls) -> httpx.AsyncClient:
        async with cls._lock:
            if cls._instance is None:
                cls._instance = httpx.AsyncClient(
                    limits=httpx.Limits(
                        max_connections=100,
                        max_keepalive_connections=20,
                    ),
                    timeout=30.0,
                )
            return cls._instance
```

**2. å¹¶è¡Œæ‰¹é‡å¤„ç†**

```python
# æ”¹è¿› async_batch_process.py
async def process_batch_parallel(
    urls: list[str],
    max_concurrency: int = 5,
) -> list[Article]:
    """å¹¶è¡Œæ‰¹é‡å¤„ç†"""
    semaphore = asyncio.Semaphore(max_concurrency)
    
    async def process_one(url: str) -> Article:
        async with semaphore:
            return await fetch_article_async(url)
    
    tasks = [process_one(url) for url in urls]
    return await asyncio.gather(*tasks, return_exceptions=True)
```

**3. ç¼“å­˜ä¼˜åŒ–**

```python
# æ·»åŠ å†…å­˜ç¼“å­˜ + ç£ç›˜ç¼“å­˜ä¸¤çº§ç¼“å­˜
class TwoLevelCache:
    """ä¸¤çº§ç¼“å­˜ï¼šå†…å­˜ LRU + ç£ç›˜æŒä¹…åŒ–"""
    
    def __init__(self, memory_size: int = 100, disk_path: Path = None):
        self._memory = LRUCache(memory_size)
        self._disk = DiskCache(disk_path) if disk_path else None
    
    def get(self, key: str) -> Any | None:
        # å…ˆæŸ¥å†…å­˜
        if key in self._memory:
            return self._memory[key]
        # å†æŸ¥ç£ç›˜
        if self._disk and key in self._disk:
            value = self._disk[key]
            self._memory[key] = value  # æå‡åˆ°å†…å­˜
            return value
        return None
```

---

### ç¬¬å…­é˜¶æ®µï¼šGUI é‡æ„ â­â­â­

**é—®é¢˜**ï¼š`gui/app.py` è¾¾åˆ° 233KBï¼Œéš¾ä»¥ç»´æŠ¤ã€‚

**æ”¹è¿›æ–¹æ¡ˆï¼šç»„ä»¶åŒ–æ‹†åˆ†**

```
src/wechat_summarizer/presentation/gui/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ app.py                    # ä¸»åº”ç”¨å…¥å£ï¼ˆç²¾ç®€ï¼‰
â”œâ”€â”€ components/               # UI ç»„ä»¶
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ url_input.py         # URL è¾“å…¥ç»„ä»¶
â”‚   â”œâ”€â”€ article_preview.py   # æ–‡ç« é¢„è§ˆç»„ä»¶
â”‚   â”œâ”€â”€ summary_panel.py     # æ‘˜è¦é¢æ¿
â”‚   â”œâ”€â”€ export_dialog.py     # å¯¼å‡ºå¯¹è¯æ¡†
â”‚   â””â”€â”€ settings_panel.py    # è®¾ç½®é¢æ¿
â”œâ”€â”€ viewmodels/              # è§†å›¾æ¨¡å‹ï¼ˆå·²æœ‰ï¼‰
â”œâ”€â”€ utils/                   # å·¥å…·ï¼ˆå·²æœ‰ï¼‰
â””â”€â”€ styles/                  # æ ·å¼å®šä¹‰
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ colors.py
    â””â”€â”€ fonts.py
```

---

### ç¬¬ä¸ƒé˜¶æ®µï¼šå¯è§‚æµ‹æ€§å¢å¼º â­â­

**1. OpenTelemetry é›†æˆ**

```python
# src/wechat_summarizer/infrastructure/observability/tracing.py
from opentelemetry import trace
from opentelemetry.sdk.trace import TracerProvider

tracer = trace.get_tracer(__name__)

def trace_use_case(func):
    """ç”¨ä¾‹è¿½è¸ªè£…é¥°å™¨"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        with tracer.start_as_current_span(func.__name__) as span:
            span.set_attribute("args", str(args))
            try:
                result = func(*args, **kwargs)
                span.set_status(StatusCode.OK)
                return result
            except Exception as e:
                span.set_status(StatusCode.ERROR, str(e))
                raise
    return wrapper
```

**2. Prometheus æŒ‡æ ‡**

```python
# src/wechat_summarizer/infrastructure/observability/metrics.py
from prometheus_client import Counter, Histogram

# è¯·æ±‚è®¡æ•°å™¨
ARTICLES_FETCHED = Counter(
    "articles_fetched_total",
    "Total articles fetched",
    ["source", "status"]
)

# å»¶è¿Ÿç›´æ–¹å›¾
FETCH_LATENCY = Histogram(
    "fetch_latency_seconds",
    "Article fetch latency",
    ["scraper"]
)

SUMMARY_LATENCY = Histogram(
    "summary_latency_seconds",
    "Summary generation latency",
    ["method"]
)
```

---

## ğŸ“‹ å®æ–½ä¼˜å…ˆçº§

| é˜¶æ®µ | åŠŸèƒ½ | ä¼˜å…ˆçº§ | å·¥ä½œé‡ | ä»·å€¼ |
|-----|-----|-------|-------|-----|
| 1 | MCP æœåŠ¡æ”¯æŒ | ğŸ”´ é«˜ | ä¸­ | éå¸¸é«˜ |
| 2 | å¢å¼ºæ‘˜è¦ç­–ç•¥ | ğŸ”´ é«˜ | é«˜ | é«˜ |
| 3 | è´¨é‡è¯„ä¼°å¢å¼º | ğŸŸ¡ ä¸­ | ä¸­ | é«˜ |
| 4 | æ’ä»¶ç³»ç»Ÿ | ğŸŸ¡ ä¸­ | ä¸­ | ä¸­ |
| 5 | æ€§èƒ½ä¼˜åŒ– | ğŸŸ¡ ä¸­ | ä¸­ | ä¸­ |
| 6 | GUI é‡æ„ | ğŸŸ¢ ä½ | é«˜ | ä¸­ |
| 7 | å¯è§‚æµ‹æ€§å¢å¼º | ğŸŸ¢ ä½ | ä½ | ä¸­ |

---

## ğŸ”— å‚è€ƒèµ„æº

- [MCP Python SDK](https://github.com/modelcontextprotocol/python-sdk)
- [FastMCP](https://github.com/jlowin/fastmcp) - ç®€åŒ– MCP æœåŠ¡å¼€å‘
- [RAG Summarization Best Practices](https://galileo.ai/blog/llm-summarization-strategies)
- [LLM Evaluation for Summarization](https://github.com/athina-ai/ariadne)
- [OpenTelemetry Python](https://opentelemetry.io/docs/languages/python/)

---

## ğŸ“ ä¸‹ä¸€æ­¥è¡ŒåŠ¨

1. **ç«‹å³å¯åš**ï¼šæ·»åŠ  MCP æœåŠ¡æ”¯æŒï¼ˆç¬¬ä¸€é˜¶æ®µï¼‰
2. **çŸ­æœŸç›®æ ‡**ï¼šå®ç° MapReduce åˆ†å—æ‘˜è¦
3. **ä¸­æœŸç›®æ ‡**ï¼šå®Œå–„æ’ä»¶ç³»ç»Ÿå’Œæ€§èƒ½ä¼˜åŒ–
4. **é•¿æœŸç›®æ ‡**ï¼šGUI é‡æ„å’Œå¯è§‚æµ‹æ€§å®Œå–„
